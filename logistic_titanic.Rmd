---
title: "Kaggle Titanic using penalized logistic regression"
author: "Laura Niss"
date: "7/21/2017"
output: 
  html_document:
    code_folding: hide # creates button to show code, but defaults as hidden
    toc: true
    toc_float: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(optimbase)
library(matrixcalc)
```
EM/IRLS for MLE


```{r}
H_inv <- function(w, rho, lambda, x){
  # inverse Hessian of likelihood function, if Hessian
  # singular, use scalar step size rho
  H.tmp <- -t(x) %*% w %*% x
  if(!is.singular.matrix(H.tmp)){
    H.tmp <- solve(H.tmp-2*lambda*diag(ncol(x)))}
  else{
    H.tmp <- rho}
  return(H.tmp)
}

IRLS_fit <- function(x,y,rho, lambda){
  # estimate theta using EM algorithm, IRLS
  # essentially gradient ascent
  m <- cbind(1, as.matrix(x))
  theta <- zeros(nx = ncol(m), ny = 1) # initialize theta
  norm <- 100
  i <- 1
  while (norm > 10^(-6) && i < 1000){
    eta <- t(theta) %*% t(m)
    mu <- 1 / (1+ exp(-eta))
    l <- t(m) %*% t(y - mu) - 2*lambda*theta # penalised likelihood
    w <- diag(as.vector(mu*(1-mu)))
    h_inv <- H_inv(w,rho, lambda, m) # inverse Hessian
    if (is.null(dim(h_inv))){
      theta_update <- theta + h_inv * l 
      } else {
      theta_update <- theta - h_inv %*% l}

    norm <- norm(theta-theta_update, type='F')
    theta <- theta_update
    i = i + 1
  }
  return(theta)
}

Logistic <- function(x, theta){
  # get prediction from test set
  m <- cbind(1, x)
  pred <- rep(0,nrow(m))
  for(i in 1:nrow(m)){
    if(1/(1+exp(-t(theta)%*%t(m[i,]))) >= .5){
      pred[i] = 1
    } else{
      pred[i] = 0}
  }
  return(pred)
}

error <- function(pred, true){
  # check error rate
  df <- data.frame(true,pred)
  error <- 1 - length(subset(df$pred, df$true == df$pred))/nrow(df)
  return(error) 
}
```



```{r}
#import training and testing data. 
train <- read.csv("train.csv", stringsAsFactors = FALSE)
test <- read.csv("test.csv", stringsAsFactors=FALSE)
```

First some minimal data cleaning. 

I changed place of embarkment from a factor to a numeric value. Yes, I know this is cheating,
and I probably just shouldn't include it, but my code was written as an exercise to understand
logistic regression and does not account for categroical variables like the true fancy R package would. 
This is not good practice, but this is also just for fun.

```{r}
embarked <- function(df){
  df$Embarked[df$Embarked == 'S'] = 1
  df$Embarked[df$Embarked == 'C'] = 2
  df$Embarked[df$Embarked == 'Q'] = 3
  df$Embarked[df$Embarked == ''] = 0
  return(df)
}

tr = embarked(train)
te = embarked(test)
```


Being somewhat more statistically sound, I'm going to impute missing "Age" values with the median.

```{r}
fillMedian <- function(dfVariable){
  median = median(dfVariable, na.rm = TRUE)
  missing = which(is.na(dfVariable))
  dfVariable[missing] = median
  return(dfVariable)
}

tr$Age <- fillMedian(train$Age)
te$Age <- fillMedian(test$Age)


```

I'm also going to change some variables that make since to be binary. For "Cabin" and "Sex" I'm going to code these in binary. "0" if they don't have a Cabin, "1" is they do.
"0" for male and "1" for female.

```{r}
binary <- function(dfVariable, zero, one){
  dfVariable[which(dfVariable==zero & !is.na(dfVariable))] = 0
  dfVariable[which(dfVariable!=0 & !is.na(dfVariable))] = 1  
  return(dfVariable)
}

tr$Sex <- binary(train$Sex, 'male')
te$Sex <- binary(test$Sex, 'male')

tr$Cabin <- binary(train$Cabin, '')
te$Cabin <- binary(test$Cabin, '')
```

I'm not going to use all the variables, so we'll drop the ones that don't make much sense as well as omiting
any instances with missing variables


```{r}
tr <- tr[c("Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", 'Cabin', "Embarked")]
te <- te[c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare",'Cabin', "Embarked")]
tr <- na.omit(tr)
te <- na.omit(te)

```

make everything numeric so can use matrix


```{r}
tr$Sex = as.numeric(unlist(tr$Sex))
tr$Embarked = as.numeric(unlist(tr$Embarked))
tr$Cabin = as.numeric(unlist(tr$Cabin))

te$Sex = as.numeric(unlist(te$Sex))
te$Embarked = as.numeric(unlist(te$Embarked))
te$Cabin = as.numeric(unlist(te$Cabin))
```

Functions to tranform


```{r}
tranform <- function(df){
  # logistic transformation
  tmp <- log(df[,-ncol(df)]+1)
  return(data.frame(tmp, df[,ncol(df)]))
}

standardize <- function(df){
  # standardize data
  return(data.frame(scale(df[,-ncol(df)]), df[,ncol(df)]))
}

x <- transform(tr[,-1]) # training data without class
y <- tr[,1] # class of training data
```




fit logistic regression, change rho, lambda to test fits
```{r}
# Split training data into test and train to check error rates
smp_size <- floor(0.75 * nrow(tr))

# set the seed to make your partition reproductible
set.seed(123)
trainSplit <- sample(seq_len(nrow(tr)), size = smp_size)

train_tmp <- tr[trainSplit, ]
test_tmp <- tr[-trainSplit, ]

x <- transform(train_tmp[,-1]) # training data without class
y <- train_tmp[,1] # class of training data
```

```{r}
theta = IRLS_fit(x, y, 1, 10)

x <- transform(test_tmp[,-1]) # testing data without class
prediction = Logistic(x, theta) # get prediction of testing data

err = error(prediction, test_tmp[,1]) # error rate
err
```

submission


```{r}
submit <- data.frame(PassengerId = test$PassengerId, Survived = prediction)
```

```
## Error in data.frame(PassengerId = test$PassengerId, Survived = prediction): arguments imply differing number of rows: 418, 223
```

```{r}
write.csv(submit, file = "logistic.csv", row.names = FALSE)
```

```
## Error in is.data.frame(x): object 'submit' not found
```

